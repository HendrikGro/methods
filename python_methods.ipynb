{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1debc16-0086-44ea-9e2c-69dbc55825d6",
   "metadata": {},
   "source": [
    "- find index of closest values in numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d5e8a1-0c3c-4949-941a-e573dd6ca524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = np.unravel_index(np.abs(array - value).argmin(), array.shape)\n",
    "    return array[idx],idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783cebac-1ff4-4d4e-a2f4-5d84dc82cfdf",
   "metadata": {},
   "source": [
    "- shift lon from 0-360 to -180,180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466654a4-e959-48b6-aeb4-7703482983cb",
   "metadata": {},
   "outputs": [],
   "source": [
    ".assign_coords({\"lon\": (((data.lon + 180) % 360) - 180)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb232d32-d00f-449b-b58f-eb68f943798c",
   "metadata": {},
   "source": [
    "- datetime format from datestring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeac92d-0e80-4d31-9456-ee11dd1952f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.strptime('{}'.format(data.time[i].values), '%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd34cc-7ba0-4ef0-a52f-a7d85cb6d168",
   "metadata": {},
   "source": [
    "- update font size for whole plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eee488-fac3-4e4e-94d8-0bf03a8a7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c408e09-5b06-4777-b5aa-ad20b0dcf4e6",
   "metadata": {},
   "source": [
    "- get list of all values in array of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618afcd2-34fb-4a6a-a922-3fc7f48e0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d890da5f-e516-4dbf-a4d6-d6fc7c26b066",
   "metadata": {},
   "source": [
    "- boolean indexing of two different arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542af859-2cf8-4614-8495-d2a87e06f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.in1d(data,bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b71f52-1299-4d21-bdad-91d143a8d8fc",
   "metadata": {},
   "source": [
    "- cartopy projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcac6e-b277-48ab-aac9-67c63a14d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = 45\n",
    "lat_max = 65\n",
    "lon_min = -60\n",
    "lon_max = -40\n",
    "resolution = '10m'\n",
    "central_lon, central_lat = (lon_max+lon_min)/2, (lat_max-lat_min)/2\n",
    "extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,10),subplot_kw=dict(projection=ccrs.Orthographic(central_lon, central_lat)))\n",
    "ax.coastlines()\n",
    "ax.set_extent(extent)\n",
    "gl = ax.gridlines(draw_labels=True,color='grey')\n",
    "gl.xlocator= mticker.FixedLocator(np.arange(-60,-35,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dedc444-8980-43e3-b8d5-cfc2889d1351",
   "metadata": {},
   "source": [
    "- calculate anomalies in xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8644f9-8330-4846-a16f-687236630af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ano = data.groupby('time.dayofyear') - data_mean.rename({'doy':'dayofyear'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6de3e-01b7-4b24-9a0d-7740527dd137",
   "metadata": {},
   "source": [
    "- custom legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aba9b1-0138-4c15-ad1f-eaa94b29ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "colors = ['tab:red', 'tab:blue']\n",
    "lines = [Line2D([0], [0], color=c, linewidth=3) for c in colors]\n",
    "labels = [ 'temperature', 'salinity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db610fd7-659c-4581-afff-c2a2523d54d8",
   "metadata": {},
   "source": [
    "- distance between two lat/lon points along section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef618c8-f652-41aa-a434-01870e87a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = [0]\n",
    "R = 6271e3\n",
    "lat = ole_orca.lat*np.pi/180\n",
    "lon = ole_orca.lon*np.pi/180\n",
    "for i in np.arange(1,78):\n",
    "    dlat = lat[i] - lat[i-1]\n",
    "    dlon = lon[i] - lon[i-1]\n",
    "    a = np.sin(dlat/2)*np.sin(dlat/2) + np.cos(lat[i])*np.cos(lat[i-1]) * np.sin(dlon/2)*np.sin(dlon/2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a),np.sqrt(1-a))\n",
    "    distance.append((R*c).values)\n",
    "model_distance = np.cumsum(distance)/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd82b43-424b-4490-b6e2-13f47518ad3a",
   "metadata": {},
   "source": [
    "- detrend xarray non-uniform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37efe9d-4fba-4562-8cbc-a7145720d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demean_xarray(da,dim):\n",
    "    return da - da.mean(dim=dim)\n",
    "\n",
    "def detrend_xarray(da):\n",
    "    dt = xr.apply_ufunc(\n",
    "                linear_detrend,\n",
    "                da,\n",
    "                input_core_dims=[['time']],\n",
    "                output_core_dims=[['time']],\n",
    "                vectorize=True,\n",
    "                output_dtypes=[da.dtype],\n",
    "                dask=\"parallelized\",\n",
    "            )\n",
    "    dt = dt.transpose('time','y','x')\n",
    "    return dt\n",
    "\n",
    "def linear_detrend(da):\n",
    "    ds = da.copy()\n",
    "    mask = ~np.isnan(ds)\n",
    "    if mask.sum() == 0:\n",
    "        return ds\n",
    "    else:\n",
    "        ds_masked = ds[mask]\n",
    "        time_masked = np.arange(0,len(ds))[mask]\n",
    "        coeff = np.polyfit(time_masked, ds_masked, 1)\n",
    "        trend = np.polyval(coeff, time_masked)\n",
    "        detrended = ds_masked - trend\n",
    "        ds[mask] = detrended\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d802bfc-0812-4a4d-b27c-a238b9fe2212",
   "metadata": {},
   "source": [
    "- non-uniform discrete fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8c5fb-d6d0-435f-99bf-850069ff0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nudft(data,xarray_apply=True):\n",
    "    mask = ~np.isnan(data)\n",
    "    \n",
    "    N_freq = len(data)\n",
    "    k = -N_freq//2 + np.arange(N_freq)\n",
    "    \n",
    "    data_masked = data[mask]\n",
    "    t = np.linspace(0, 1,N_freq)[mask]\n",
    "    \n",
    "    f_k = nfft.ndft_adjoint(t,data_masked,N_freq)\n",
    "    ps = np.abs(f_k)**2/N_freq**2\n",
    "    psd = ps * N_freq\n",
    "    freq = k/N_freq\n",
    "    if xarray_apply == True:\n",
    "        return np.stack((freq,f_k,ps,psd),axis=-1)\n",
    "    elif xarray_apply==False:\n",
    "        return freq,f_k,ps,psd,t\n",
    "    \n",
    "def spectral_analysis(da):\n",
    "    dt = xr.apply_ufunc(\n",
    "                nudft,\n",
    "                da,\n",
    "                input_core_dims=[['time']],\n",
    "                output_core_dims=[['freq','dim0']],\n",
    "                vectorize=True,\n",
    "                output_dtypes=[da.dtype],\n",
    "                dask=\"parallelized\",\n",
    "                dask_gufunc_kwargs={'output_sizes':{'freq':(744,4)}}\n",
    "            )\n",
    "    dt = xr.Dataset(coords={\n",
    "        'lat':(['y','x'],dt['lat'].data),\n",
    "        'lon':(['y','x'],dt['lon'].data),\n",
    "        'freq':dt[0,0,:,0].data\n",
    "    },data_vars={\n",
    "        'f_k':(['y','x','freq'],dt.isel(dim0=1).data),\n",
    "        'ps':(['y','x','freq'],dt.isel(dim0=2).data),\n",
    "        'psd':(['y','x','freq'],dt.isel(dim0=3).data)\n",
    "\n",
    "    })\n",
    "    dt = dt.transpose('freq','y','x')\n",
    "    dt = dt.where(dt!=0)\n",
    "    return dt\n",
    "\n",
    "test = spectral_analysis(velocity.u_detrended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2642ed-96ec-44da-86fa-88f0501d8f98",
   "metadata": {},
   "source": [
    "- xmovie example custom plotfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95438a15-fb04-4a32-96fe-8fd18b584cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "def custom_plotfunc(ds,fig,tt,framedim='time',**kwargs):\n",
    "    ax = fig.subplots(subplot_kw={'projection':ccrs.PlateCarree()})\n",
    "    ds.isel({framedim:tt}).plot.quiver('lon','lat','u','v',ax=ax)\n",
    "    ax.add_feature(cfeature.LAND, facecolor='grey',edgecolor='black')\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    return None,None\n",
    "    \n",
    "# mov = Movie(velocity,custom_plotfunc,input_check=False)\n",
    "# mov.save('movie_2015.mp4',overwrite_existing=True,framerate=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc161f-e626-4397-93bb-690a213772da",
   "metadata": {},
   "source": [
    "- spatial correlation xarray apply_ufunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebbde2-0ee2-431c-84b7-dad4922daf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import dask\n",
    "\n",
    "#stats.personr only works on dataarrays, so select your variable at one point\n",
    "data = xr.open_dataset('subset.nc').sst \n",
    "\n",
    "#maybe mfdataset helps for huge datasets and then parallization; 39 is the size of time, you want all tim points to be in one chunk\n",
    "# data = xr.open_mfdataset('subset.nc',chunks={'time':39,'lat':100,'lon':100}).sst \n",
    "\n",
    "#stats.pearsonr doesnt allow nan inputs, so put nan to 0; it then returns nan again for correlation along constant arrays\n",
    "data = data.fillna(0)\n",
    "\n",
    "def correlation(data1,data2):\n",
    "    # data1 is the spatial field you want to correlate to\n",
    "    # data2 is your single time series\n",
    "    # calculates the correlation coefficient and p_value\n",
    "    # returns the result as a numpy array, because the initial output of the function is of a weird PearsonRResult class, which doesnt work in apply_ufunc\n",
    "    result = stats.pearsonr(data1,data2)\n",
    "    return np.stack((result[0],result[1]), axis=-1)\n",
    "\n",
    "# apply_ufunc takes the function you want to apply and then the necessary input arguments to that function\n",
    "# so data is your spatial field and then your single time series (I just selected one pointfrom my field)\n",
    "# the input_core_dimensions basically mean along which dimension your function is applied on\n",
    "# the output dimension is necesarry because the correlation output is of size 2\n",
    "# dask='parallelized' makes it faster, but needs some additional arguments for your output\n",
    "\n",
    "result = xr.apply_ufunc(
    "correlation",
    "data",
    "data.isel(lat=50,lon=50)",
    "input_core_dims=[['time'],['time']]",
    "output_core_dims=[['statistic']]",
    "vectorize=True",
    "dask='parallelized'",
    "output_dtypes=[np.dtype(float)]",
    "dask_gufunc_kwargs={'output_sizes':{'statistic':2}})\n",
    "\n",
    "# make xarray dataset of the output, because the output has r and p along one extra dimension, so assign them to single variables\n",
    "statistics = xr.Dataset(coords={'lat':result.lat,'lon':result.lon}, data_vars = {\n",
    "    'corrcoef':result[:,:,0],\n",
    "    'p_value':result[:,:,1]\n",
    "})\n",
    "\n",
    "# necessary if you use mfdatasets, so you finally compute the correlation for each chunk\n",
    "# statistics = statistics.compute()\n",
    "\n",
    "statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
